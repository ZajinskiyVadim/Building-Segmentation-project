"""
–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è inference —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –º–∞—Å—à—Ç–∞–±–∞
"""

import torch
import numpy as np
from typing import Tuple, Optional, Union, Dict
from pathlib import Path
from PIL import Image

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥—É–ª–µ–π
from inference import predict_large_image as _predict_large_image
from area_calculator_advanced import AreaCalculatorAdvanced


def predict_and_calculate_area(
    model: torch.nn.Module,
    image_source: Union[str, Path, np.ndarray],
    device: torch.device,
    patch_size: int = 512,
    stride: int = 512,
    use_amp: bool = True,
    threshold: float = 0.5,
    pixel_size_m: Optional[float] = None,
    auto_extract_scale: bool = True
) -> Dict:
    """
    –ü–æ–ª–Ω—ã–π pipeline: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è + –†–∞—Å—á—ë—Ç –ø–ª–æ—â–∞–¥–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –º–∞—Å—à—Ç–∞–±–æ–º
    
    Args:
        model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        image_source: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (str/Path) –∏–ª–∏ numpy array
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cuda/cpu)
        patch_size: –†–∞–∑–º–µ—Ä –ø–∞—Ç—á–∞ –¥–ª—è inference
        stride: –®–∞–≥ –ø–∞—Ç—á–µ–π
        use_amp: Mixed precision
        threshold: –ü–æ—Ä–æ–≥ –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏–∏
        pixel_size_m: –Ø–≤–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–± (–µ—Å–ª–∏ None - –∞–≤—Ç–æ)
        auto_extract_scale: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å –º–∞—Å—à—Ç–∞–± –∏–∑ GeoTIFF
    
    Returns:
        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            - pred_mask: –ë–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞
            - pred_probs: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            - areas: –°–ª–æ–≤–∞—Ä—å —Å –ø–ª–æ—â–∞–¥—è–º–∏
            - pixel_size_m: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–±
    """
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if isinstance(image_source, (str, Path)):
        image_path = Path(image_source)
        image = np.array(Image.open(image_path).convert('RGB'))
        has_path = True
    else:
        image = image_source
        image_path = None
        has_path = False
    
    # 2. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –º–∞—Å—à—Ç–∞–±–∞!)
    pred_mask, pred_probs = _predict_large_image(
        model=model,
        image=image,
        device=device,
        patch_size=patch_size,
        stride=stride,
        use_amp=use_amp,
        threshold=threshold
    )
    
    # 3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞
    if pixel_size_m is not None:
        # –Ø–≤–Ω–æ —É–∫–∞–∑–∞–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        calculator = AreaCalculatorAdvanced(pixel_size_m=pixel_size_m)
        scale_source = f"manual ({pixel_size_m}m)"
        
    elif auto_extract_scale and has_path and image_path.suffix.lower() in ['.tif', '.tiff']:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –∏–∑ GeoTIFF
        try:
            calculator = AreaCalculatorAdvanced.from_geotiff(image_path)
            scale_source = f"geotiff ({calculator.pixel_size_m}m)"
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–∞—Å—à—Ç–∞–± –∏–∑ GeoTIFF: {e}")
            print(f"    –ò—Å–ø–æ–ª—å–∑—É—é –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.3 –º/–ø–∏–∫—Å–µ–ª—å")
            calculator = AreaCalculatorAdvanced(pixel_size_m=0.3)
            scale_source = "default (0.3m)"
    else:
        # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (INRIA)
        calculator = AreaCalculatorAdvanced(pixel_size_m=0.3)
        scale_source = "default (0.3m)"
    
    # 4. –†–∞—Å—á—ë—Ç –ø–ª–æ—â–∞–¥–∏
    areas = calculator.calculate_area(pred_mask)
    
    # 5. –†–µ–∑—É–ª—å—Ç–∞—Ç
    return {
        'pred_mask': pred_mask,
        'pred_probs': pred_probs,
        'areas': areas,
        'pixel_size_m': calculator.pixel_size_m,
        'scale_source': scale_source,
        'image_shape': image.shape
    }


def batch_predict_and_calculate(
    model: torch.nn.Module,
    image_paths: list,
    device: torch.device,
    **kwargs
) -> list:
    """
    Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –º–∞—Å—à—Ç–∞–±–æ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Args:
        model: –ú–æ–¥–µ–ª—å
        image_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        **kwargs: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è predict_and_calculate_area
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    results = []
    
    for img_path in image_paths:
        print(f"\nüì∑ –û–±—Ä–∞–±–æ—Ç–∫–∞: {Path(img_path).name}")
        
        result = predict_and_calculate_area(
            model=model,
            image_source=img_path,
            device=device,
            **kwargs
        )
        
        areas = result['areas']
        print(f"   –ú–∞—Å—à—Ç–∞–±: {result['pixel_size_m']} –º/–ø–∏–∫—Å–µ–ª—å ({result['scale_source']})")
        print(f"   –ü–ª–æ—â–∞–¥—å: {areas['area_ha']:.2f} –≥–∞ ({areas['area_m2']:.0f} –º¬≤)")
        print(f"   –ü–æ–∫—Ä—ã—Ç–∏–µ: {areas['coverage_percent']:.2f}%")
        
        results.append(result)
    
    return results


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == '__main__':
    import sys
    sys.path.append('src')
    
    from model import create_model
    from inference import load_model_from_checkpoint
    
    print("="*80)
    print("–¢–µ—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∞")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nüì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (–ø—Ä–∏–º–µ—Ä)
    model_config = {
        'architecture': 'unet',
        'encoder': 'resnet50',
        'encoder_weights': 'imagenet',
        'in_channels': 3,
        'classes': 1
    }
    
    model = create_model(model_config, device)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint
    checkpoint_path = "models/checkpoints/best_model.pth"
    if Path(checkpoint_path).exists():
        model = load_model_from_checkpoint(checkpoint_path, model, device)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {checkpoint_path}")
    else:
        print(f"‚ö†Ô∏è  Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω: {checkpoint_path}")
        print("   –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Å—Ç–∞)")
    
    # –¢–µ—Å—Ç 1: –° –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –º–∞—Å—à—Ç–∞–±–∞
    print("\n" + "="*80)
    print("–¢–µ—Å—Ç 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞ –∏–∑ GeoTIFF")
    print("="*80)
    
    test_image = "data/AerialImageDataset/train/images/austin1.tif"
    
    if Path(test_image).exists():
        result = predict_and_calculate_area(
            model=model,
            image_source=test_image,
            device=device,
            patch_size=512,
            stride=512,
            threshold=0.5,
            auto_extract_scale=True  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!
        )
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   –ú–∞—Å—à—Ç–∞–±: {result['pixel_size_m']} –º/–ø–∏–∫—Å–µ–ª—å")
        print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {result['scale_source']}")
        print(f"   –ü–ª–æ—â–∞–¥—å: {result['areas']['area_ha']:.4f} –≥–∞")
        print(f"   –ü–æ–∫—Ä—ã—Ç–∏–µ: {result['areas']['coverage_percent']:.2f}%")
    else:
        print(f"‚ö†Ô∏è  –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {test_image}")
    
    # –¢–µ—Å—Ç 2: –° —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –º–∞—Å—à—Ç–∞–±–∞
    print("\n" + "="*80)
    print("–¢–µ—Å—Ç 2: –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞")
    print("="*80)
    
    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    test_array = np.random.randint(0, 255, (1000, 1000, 3), dtype=np.uint8)
    
    result = predict_and_calculate_area(
        model=model,
        image_source=test_array,
        device=device,
        pixel_size_m=0.5,  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º!
        auto_extract_scale=False
    )
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   –ú–∞—Å—à—Ç–∞–±: {result['pixel_size_m']} –º/–ø–∏–∫—Å–µ–ª—å")
    print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {result['scale_source']}")
    
    # –¢–µ—Å—Ç 3: Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞
    print("\n" + "="*80)
    print("–¢–µ—Å—Ç 3: Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞")
    print("="*80)
    
    test_images = [
        "data/AerialImageDataset/train/images/austin1.tif",
        "data/AerialImageDataset/train/images/chicago1.tif",
        "data/AerialImageDataset/train/images/vienna1.tif"
    ]
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
    existing_images = [img for img in test_images if Path(img).exists()]
    
    if existing_images:
        results = batch_predict_and_calculate(
            model=model,
            image_paths=existing_images,
            device=device,
            patch_size=512,
            stride=512,
            auto_extract_scale=True
        )
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    else:
        print("‚ö†Ô∏è  –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    print("\n" + "="*80)
    print("‚úì –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print("="*80)
